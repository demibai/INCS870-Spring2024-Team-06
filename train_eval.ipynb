{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import RFE, RFECV, VarianceThreshold, SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from configparser import ConfigParser\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = ConfigParser()\n",
    "constants.read(\"constants.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = constants.get(\"CONSTANTS\", \"DATASET_PATH\")\n",
    "figures_path = constants.get(\"CONSTANTS\", \"FIGURES_PATH\")\n",
    "models_path = constants.get(\"CONSTANTS\", \"MODELS_PATH\")\n",
    "train_file = constants.get(\"CONSTANTS\", \"TRAIN_FILE\")\n",
    "test_file = constants.get(\"CONSTANTS\", \"TEST_FILE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training dataset and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_set_path = os.path.join(dataset_path, train_file)\n",
    "    test_set_path = os.path.join(dataset_path, test_file)\n",
    "    train_data = pd.read_csv(train_set_path)\n",
    "    test_data = pd.read_csv(test_set_path)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pre-trained machine learning model stored in a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_pickle(model_path):\n",
    "    model = joblib.load(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the dataset<br>\n",
    "Transform original data type into a categorical data type.<br>\n",
    "Then encode the categories as integer codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_num(data):\n",
    "    # protocol\n",
    "    data[\"proto\"] = data[\"proto\"].astype(\"category\")\n",
    "    data[\"proto\"] = data[\"proto\"].cat.codes\n",
    "\n",
    "    # service\n",
    "    data[\"service\"] = data[\"service\"].astype(\"category\")\n",
    "    data[\"service\"] = data[\"service\"].cat.codes\n",
    "\n",
    "    # state\n",
    "    data[\"state\"] = data[\"state\"].astype(\"category\")\n",
    "    data[\"state\"] = data[\"state\"].cat.codes\n",
    "\n",
    "    # attack category\n",
    "    data[\"attack_cat\"] = data[\"attack_cat\"].astype(\"category\")\n",
    "    data[\"attack_cat\"] = data[\"attack_cat\"].cat.codes\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(x_train, y_train, x_test, method, k=None, cv=None):\n",
    "    # Feature selection sub-routine\n",
    "    feature_selection_time = 0\n",
    "    if method == \"rfe\" or method == \"rfecv\":\n",
    "        # Recursive Feature Elimination\n",
    "        if not k:\n",
    "            k = 20\n",
    "        else:\n",
    "            k = int(k)\n",
    "        print(\"[Feature Selection] Using Recursive Feature Elimination,\", \"selecting\", str(k), \"features.\")\n",
    "        start_time = time.time()\n",
    "        model = XGBClassifier()\n",
    "        if method == \"rfecv\":\n",
    "            cv = 5 if not cv else int(cv)\n",
    "            print(\"[Feature Selection] Using RFECV, splitting dataset into %d folds.\" % cv)\n",
    "            rfe = RFECV(model, step=1, min_features_to_select=k,cv=cv)\n",
    "        else:\n",
    "            rfe = RFE(model, n_features_to_select=k)\n",
    "        fit = rfe.fit(x_train, y_train)\n",
    "        selected_features = fit.get_support(indices=True)\n",
    "        x_train = x_train[x_train.columns[selected_features]]\n",
    "        x_test = x_test[x_test.columns[selected_features]]\n",
    "        end_time = time.time()\n",
    "        feature_selection_time = round(end_time - start_time, 2)\n",
    "        print(\"[Feature Selection] RFE took\", feature_selection_time, \"seconds\")\n",
    "    elif method == \"variance_threshold\":\n",
    "        if not k:\n",
    "            k = 0.0\n",
    "        print(\"[Feature Selection] Using Variance Threshold\", \"using\", str(k), \"as threshold.\")\n",
    "        start_time = time.time()\n",
    "        vt = VarianceThreshold(threshold=k)\n",
    "        fit = vt.fit(x_train, y_train)\n",
    "        selected_features = fit.get_support(indices=True)\n",
    "        x_train = x_train[x_train.columns[selected_features]]\n",
    "        x_test = x_test[x_test.columns[selected_features]]\n",
    "        end_time = time.time()\n",
    "        feature_selection_time = round(end_time - start_time, 2)\n",
    "        print(\"[Feature Selection] Variance Threshold took\", feature_selection_time, \"seconds\")\n",
    "    elif method == \"chi2\":\n",
    "        if not k:\n",
    "            k = 20\n",
    "        else:\n",
    "            k = int(k)\n",
    "        print(\"[Feature Selection] Using SelectKBest,\", \"selecting\", str(k), \"features.\")\n",
    "        start_time = time.time()\n",
    "        skb = SelectKBest(chi2, k=k)\n",
    "        fit = skb.fit(x_train, y_train)\n",
    "        selected_features = fit.get_support(indices=True)\n",
    "        x_train = x_train[x_train.columns[selected_features]]\n",
    "        x_test = x_test[x_test.columns[selected_features]]\n",
    "        end_time = time.time()\n",
    "        feature_selection_time = round(end_time - start_time, 2)\n",
    "        print(\"[Feature Selection] SelectKBest took\", feature_selection_time, \"seconds\")\n",
    "    elif method == \"anova\":\n",
    "        if not k:\n",
    "            k = 20\n",
    "        else:\n",
    "            k = int(k)\n",
    "        print(\"[Feature Selection] Using SelectKBest,\", \"selecting\", str(k), \"features.\")\n",
    "        start_time = time.time()\n",
    "        skb = SelectKBest(f_classif, k=k)\n",
    "        fit = skb.fit(x_train, y_train)\n",
    "        selected_features = fit.get_support(indices=True)\n",
    "        x_train = x_train[x_train.columns[selected_features]]\n",
    "        x_test = x_test[x_test.columns[selected_features]]\n",
    "        end_time = time.time()\n",
    "        feature_selection_time = round(end_time - start_time, 2)\n",
    "        print(\"[Feature Selection] SelectKBest took\", feature_selection_time, \"seconds\")\n",
    "    elif method == \"mutual_information\":\n",
    "        if not k:\n",
    "            k = 20\n",
    "        else:\n",
    "            k = int(k)\n",
    "        print(\"[Feature Selection] Using SelectKBest,\", \"selecting\", str(k), \"features.\")\n",
    "        start_time = time.time()\n",
    "        skb = SelectKBest(mutual_info_classif, k=k)\n",
    "        fit = skb.fit(x_train, y_train)\n",
    "        selected_features = fit.get_support(indices=True)\n",
    "        x_train = x_train[x_train.columns[selected_features]]\n",
    "        x_test = x_test[x_test.columns[selected_features]]\n",
    "        end_time = time.time()\n",
    "        feature_selection_time = round(end_time - start_time, 2)\n",
    "        print(\"[Feature Selection] SelectKBest took\", feature_selection_time, \"seconds\")\n",
    "    else:\n",
    "        print(\"[Feature Selection] No feature selection method specified. Using all features.\")\n",
    "    print(\"[Feature Selection] Train dataset shape after feature selection:\", x_train.shape)\n",
    "    print(\"[Feature Selection] Test dataset shape after feature selection:\", x_test.shape)\n",
    "    return x_train, x_test, feature_selection_time, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(**kwargs):\n",
    "    # Load dataset\n",
    "    train_data, test_data = load_dataset()\n",
    "    train_data = cat_to_num(train_data)\n",
    "    test_data = cat_to_num(test_data)\n",
    "    print(\"[Dataset] Train dataset shape:\", train_data.shape)\n",
    "    print(\"[Dataset] Test dataset shape:\", test_data.shape)\n",
    "    y_train = train_data[\"attack_cat\"]\n",
    "    x_train = train_data.drop([\"id\", \"label\", \"attack_cat\"], axis=1)\n",
    "    y_test = test_data[\"attack_cat\"]\n",
    "    x_test = test_data.drop([\"id\", \"label\", \"attack_cat\"], axis=1)\n",
    "    k = kwargs.get(\"k\", None)\n",
    "    x_train, x_test, fs_time, k = feature_selection(x_train, y_train, x_test,\n",
    "                                                    kwargs.get(\"method\", None), float(k) if k else None)\n",
    "    if kwargs.get(\"model_path\", None):\n",
    "        # Load model from local file\n",
    "        model = load_model_from_pickle(kwargs.get(\"model_path\"))\n",
    "        print(\"[Model] Model loaded from\", kwargs.get(\"model_path\"))\n",
    "        model_features = model.get_booster().feature_names\n",
    "        y_pred = model.predict(x_test[model_features])\n",
    "        VERBOSE = False\n",
    "    else:\n",
    "        # Model training\n",
    "        start_time = time.time()\n",
    "        xgboost_params = {\n",
    "            \"objective\": \"multi:softprob\",\n",
    "            \"min_child_weight\": 1,\n",
    "            \"max_depth\": 6,\n",
    "            \"num_class\": 10,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"n_estimators\": 200,\n",
    "            \"subsample\": 0.5,\n",
    "            \"colsample_bytree\": 0.5,\n",
    "            \"reg_lambda\": 1,\n",
    "            \"reg_alpha\": 0\n",
    "        }\n",
    "        model = XGBClassifier(**xgboost_params)\n",
    "        model.fit(x_train, y_train)\n",
    "        end_time = time.time()\n",
    "        model_training_time = round(end_time - start_time, 2)\n",
    "        print(\"[Model] Training time:\", model_training_time, \"seconds\")\n",
    "        y_pred = model.predict(x_test)\n",
    "        VERBOSE = True\n",
    "    timestamp = int(time.time())\n",
    "    if not kwargs.get(\"model_path\", None):\n",
    "        # Freeze model to disk\n",
    "        print(\"[Model] Freezing params to disk\")\n",
    "        model_name = model.__class__.__name__.lower()\n",
    "        file_prefix = str(timestamp) + \"_\" + model_name + \"_\" + kwargs.get(\"method\", \"none\") + \"_\"\n",
    "        file_prefix += str(k) if k else \"all\"\n",
    "        joblib.dump(model, models_path + file_prefix + \"_model\" + \".pkl\")\n",
    "        print(\"[Model] Model saved to\", models_path + file_prefix + \".pkl\")\n",
    "    else:\n",
    "        file_prefix = str(timestamp) + \"_loaded_model\"\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"[Model] Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "    # Classification report\n",
    "    print(\"[Model] Classification report\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    if VERBOSE:\n",
    "        # Verbose report\n",
    "        report_df.loc[\"\"] = \"\"\n",
    "        report_df.loc[\"model_name\"] = model_name\n",
    "        report_df.loc[\"model_training_time\"] = model_training_time\n",
    "        report_df.loc[\"feature_selection_method\"] = kwargs.get(\"method\", \"none\")\n",
    "        report_df.loc[\"k\"] = k\n",
    "        report_df.loc[\"feature_selection_time\"] = fs_time\n",
    "        report_df.loc[\"accuracy\"] = accuracy\n",
    "        report_df.loc[\"recall\"] = report_df.loc[\"weighted avg\"][\"recall\"]\n",
    "        report_df.loc[\"precision\"] = report_df.loc[\"weighted avg\"][\"precision\"]\n",
    "        report_df.loc[\"f1_score\"] = report_df.loc[\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "    # Save report to disk\n",
    "    report_df.to_csv(\"reports/\" + file_prefix + \"_report.csv\")\n",
    "\n",
    "    # Plot feature importance\n",
    "    feature_importance = model.feature_importances_\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "    plt.yticks(pos, x_train.columns[sorted_idx])\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.savefig(\"figures/\" + file_prefix + \"_importance.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
